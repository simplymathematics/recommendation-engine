---
title: "Project 5"
output: 
  html_notebook:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=TRUE, warning=FALSE, cache = TRUE)
```


# Using Recommender Systems for Facial Reognition
[Source](www.irbnet.de/daten/iconda/CIB11300.pdf)
[Source](https://www.math.cuhk.edu.hk/~lmlui/CaoSVDintro.pdf)


# Data: 
[Source](https://courses.media.mit.edu/2004fall/mas622j/04.projects/faces/)

The data comes from MIT and treats each image as a vector. I had to clean the data by removing the known bad rows.


```{r, eval=T, echo=T, warning=F, message=F}
faces <- read.csv("../faces/faceR", sep = " ", header = F)
faces$V1 <- NULL
faces$ID <- as.integer(faces$V2)
faces$V2 <- NULL
faces <- faces[!faces$ID == 1228,]
faces <- faces[!faces$ID == 1808,]
faces <- faces[!faces$ID == 4056,]
faces <- faces[!faces$ID == 4135,]
faces <- faces[!faces$ID == 4136,]
faces <- faces[!faces$ID == 5004,]
faces[is.na(faces)] <- 0
train <- faces
ID <- train$ID
train$ID <- NULL
dim(train)
train
```

I processed the data by centering it and scaling it to be between 0 and 1.

```{r}
library(caret)
processed <- preProcess(train, method = c("scale", "center" ))


train <- predict(processed, train)



```

I removed the corrupted data from the training set, as mentioned in the documentation.

```{r}
faces <- read.csv("../faces/faceS", sep = " ", header = F)
faces$V1 <- NULL
faces$ID <- as.integer(faces$V2)
faces$V2 <- NULL
faces <- faces[!faces$ID == 1228,]
faces <- faces[!faces$ID == 1808,]
faces <- faces[!faces$ID == 4056,]
faces <- faces[!faces$ID == 4135,]
faces <- faces[!faces$ID == 4136,]
faces <- faces[!faces$ID == 5004,]
faces[is.na(faces)] <- 0
test <- faces
test$ID <- NULL
test <- test[1:2103,]
processed <- preProcess(train, method = c("center", "scale"))
test <- predict(processed, test)
```

I then used another factorization technique, called linear discriminant analysis, to build the model. LDA maximizes the difference between classes by acting on the component space defined above.
 

Instead of spark, I will use a local cluster for this analysis. I have 8 cores, so I'm making 8 clusters. Further gains would need a specific type of cloud architecture and highly-optimized spark code. However, on the order of 10s of Gigabytes, doing these calculations on a bigger, distribute cluster (like Spark), becomes useful.

```{r }
library(doParallel)
cl <- makePSOCKcluster(8)
registerDoParallel(cl)
```

```{r}
model1 <- train(cleaned, train.labels, method = "lda", metric = "Accuracy", trace = FALSE)
model1$results
```
 I was able to get an accuracy of 82% in a run-time of a few seconds by using the linear algebra techniques. It's scary how trivial this is.




